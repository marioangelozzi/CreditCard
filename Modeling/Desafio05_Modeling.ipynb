{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing necessary libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install mixed-naive-bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic libs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# show all available columns\n",
    "pd.set_option('display.max_columns', 200)\n",
    "# show all available rows\n",
    "pd.set_option('display.max_rows', 200)\n",
    "\n",
    "# Data Prep\n",
    "from feature_engine.categorical_encoders import CountFrequencyCategoricalEncoder\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, OneHotEncoder, OrdinalEncoder, LabelEncoder\n",
    "from category_encoders import TargetEncoder\n",
    "\n",
    "# import classifiers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from mixed_naive_bayes import MixedNB\n",
    "\n",
    "# ensemble models \n",
    "from sklearn.ensemble import AdaBoostClassifier, VotingClassifier, StackingClassifier, ExtraTreesClassifier\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "import lightgbm as lgb\n",
    "\n",
    "# neural network model\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# otimization features\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "# Validation and metrics\n",
    "from sklearn.model_selection import cross_val_predict, learning_curve, KFold, LeaveOneOut, cross_validate, validation_curve\n",
    "from sklearn.metrics import precision_recall_curve, log_loss, make_scorer\n",
    "from sklearn.metrics import auc, confusion_matrix, roc_curve, roc_auc_score\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, classification_report, f1_score, fbeta_score\n",
    "\n",
    "# statistics\n",
    "from scipy.stats import loguniform, uniform\n",
    "\n",
    "# models\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# warnig treatments\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Charging and dividing DataFrame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charging dataframe\n",
    "PATH = 'D:\\DataScience\\Python\\Jupyter\\Desafio05\\Data\\Processed'\n",
    "FILE = '\\Default_Credit_Card_processed_toModel.csv'\n",
    "\n",
    "df_credit_card = pd.read_csv(PATH + FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Target constraint\n",
    "TARGET = 'Default'\n",
    "\n",
    "# Sharing training and testing data\n",
    "df_train, df_test = train_test_split(df_credit_card, stratify=df_credit_card[TARGET], test_size=0.2, random_state=42)\n",
    "\n",
    "# Isolating target variable\n",
    "X_train = df_train.drop(TARGET, axis=1)\n",
    "y_train = df_train[TARGET]\n",
    "\n",
    "X_test = df_test.drop(TARGET, axis=1)\n",
    "y_test = df_test[TARGET]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the pipeline strategy of variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Default</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>PAY_6</th>\n",
       "      <th>BILL_AMT1</th>\n",
       "      <th>BILL_AMT2</th>\n",
       "      <th>BILL_AMT3</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>160000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>161771</td>\n",
       "      <td>172632</td>\n",
       "      <td>168541</td>\n",
       "      <td>164310</td>\n",
       "      <td>15000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6100</td>\n",
       "      <td>12300</td>\n",
       "      <td>6100</td>\n",
       "      <td>-0.504010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>150000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.381528</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Default  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  \\\n",
       "0        0     160000    2          2         2   33      2      2      3   \n",
       "1        0     150000    2          1         2   34      1     -1     -1   \n",
       "\n",
       "   PAY_4  PAY_5  PAY_6  BILL_AMT1  BILL_AMT2  BILL_AMT3  BILL_AMT4  PAY_AMT1  \\\n",
       "0      2      0      0     161771     172632     168541     164310     15000   \n",
       "1     -2     -2     -2          0         53          0          0        53   \n",
       "\n",
       "   PAY_AMT2  PAY_AMT3  PAY_AMT4  PAY_AMT5  PAY_AMT6     score  \n",
       "0         0         0      6100     12300      6100 -0.504010  \n",
       "1         0         0         0         0         0 -0.381528  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_credit_card.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.50401004, -0.38152765, -0.3779966 , ..., -0.46404359,\n",
       "       -0.39293201, -0.43378021])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_credit_card['score'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1]\n",
      "[2 1 3 4]\n",
      "[ 2  1  0 -1  3 -2  4  6  5  8  7]\n",
      "[ 2 -1  0 -2  3  1  4  5  7  6  8]\n",
      "[ 3 -1  0  2 -2  4  7  6  5  1  8]\n",
      "[ 2 -2  0 -1  3  7  4  5  1  8  6]\n",
      "[ 0 -2 -1  2  7  5  4  3  6  8]\n",
      "[ 0 -2  2 -1  6  4  3  7  5  8]\n"
     ]
    }
   ],
   "source": [
    "for col in df_credit_card[['SEX', 'EDUCATION', 'PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6']]:\n",
    "    print(df_credit_card[col].unique())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    ">> Defining data transformation for modeling:\n",
    "\n",
    "Default - target variable\n",
    "\n",
    "LIMIT_BAL - Standard Scaler \n",
    "SEX - One hot encoder\n",
    "EDUCATION - Category enconder\n",
    "MARRIAGE - One hot enconder \n",
    "AGE - MinMax Scaler\n",
    "PAY_0 - Target enconder\n",
    "PAY_2 - Target enconder \n",
    "PAY_3 - Target enconder\n",
    "PAY_4 - Target enconder\n",
    "PAY_5 - Target enconder \n",
    "PAY_6 - Target enconder \n",
    "BILL_AMT1 - Standard Scaler\n",
    "BILL_AMT2 - Standard Scaler\n",
    "BILL_AMT3 - Standard Scaler\n",
    "BILL_AMT4 - Standard Scaler\n",
    "PAY_AMT1 - Standard Scaler\n",
    "PAY_AMT2 - Standard Scaler\n",
    "PAY_AMT3 - Standard Scaler\n",
    "PAY_AMT4 - Standard Scaler\n",
    "PAY_AMT5 - Standard Scaler\n",
    "PAY_AMT6 - Standard Scaler\n",
    "score - Standard Scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing objects X_Train\n",
    "X_train['SEX'] = X_train['SEX'].astype('object')\n",
    "X_train['MARRIAGE'] = X_train['MARRIAGE'].astype('object')\n",
    "X_train['EDUCATION'] = X_train['EDUCATION'].astype('object')\n",
    "X_train['PAY_0'] = X_train['PAY_0'].astype('object')\n",
    "X_train['PAY_2'] = X_train['PAY_2'].astype('object')\n",
    "X_train['PAY_3'] = X_train['PAY_3'].astype('object')\n",
    "X_train['PAY_4'] = X_train['PAY_4'].astype('object')\n",
    "X_train['PAY_5'] = X_train['PAY_5'].astype('object')\n",
    "X_train['PAY_6'] = X_train['PAY_6'].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing objects X_test\n",
    "X_test['SEX'] = X_test['SEX'].astype('object')\n",
    "X_test['MARRIAGE'] = X_test['MARRIAGE'].astype('object')\n",
    "X_test['EDUCATION'] = X_test['EDUCATION'].astype('object')\n",
    "X_test['PAY_0'] = X_test['PAY_0'].astype('object')\n",
    "X_test['PAY_2'] = X_test['PAY_2'].astype('object')\n",
    "X_test['PAY_3'] = X_test['PAY_3'].astype('object')\n",
    "X_test['PAY_4'] = X_test['PAY_4'].astype('object')\n",
    "X_test['PAY_5'] = X_test['PAY_5'].astype('object')\n",
    "X_test['PAY_6'] = X_test['PAY_5'].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining pipes\n",
    "vars_minmax = ['AGE']\n",
    "vars_encs = ['SEX', 'MARRIAGE']\n",
    "vars_cats = ['EDUCATION']\n",
    "vars_targ = ['PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6']\n",
    "vars_stds = ['LIMIT_BAL', 'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4',\n",
    "             'PAY_AMT5', 'PAY_AMT6', 'score']\n",
    "\n",
    "# Charging pipelines\n",
    "pipe_num_min_max = ('min_max_scaler', MinMaxScaler(), vars_minmax)\n",
    "pipe_cat_one_hot = ('one_hot_encoder', OneHotEncoder(handle_unknown='ignore'), vars_encs)\n",
    "pipe_cat_ordinal = ('ordinal_encoder', OrdinalEncoder(), vars_cats)\n",
    "pipe_cat_target = ('target_encoder', TargetEncoder(), vars_targ)\n",
    "pipe_num_stds = ('standard_scaler', StandardScaler(), vars_stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elaborating transformer flow \n",
    "transformers = [pipe_num_min_max,\n",
    "                pipe_cat_one_hot,\n",
    "                pipe_cat_ordinal,\n",
    "                pipe_cat_target,\n",
    "                pipe_num_stds]\n",
    "pre_processador = ColumnTransformer(transformers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../src/modeling')\n",
    "\n",
    "# import lib Model_Evaluation that has execute model and ranking model\n",
    "# excute model is a function that runs the basic models in order to future decision\n",
    "# ranking model elaborates a dataframe that has an ordernation from the best model to the worst one\n",
    "import Model_Evaluation as me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[11:50:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:50:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:50:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:50:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:50:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:50:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:50:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:50:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:50:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:50:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:50:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\ttotal: 5.29ms\tremaining: 259ms\n",
      "1:\ttotal: 10.7ms\tremaining: 256ms\n",
      "2:\ttotal: 15.9ms\tremaining: 249ms\n",
      "3:\ttotal: 21.9ms\tremaining: 251ms\n",
      "4:\ttotal: 27ms\tremaining: 243ms\n",
      "5:\ttotal: 32.3ms\tremaining: 237ms\n",
      "6:\ttotal: 37.2ms\tremaining: 228ms\n",
      "7:\ttotal: 42ms\tremaining: 221ms\n",
      "8:\ttotal: 46.8ms\tremaining: 213ms\n",
      "9:\ttotal: 51.8ms\tremaining: 207ms\n",
      "10:\ttotal: 57.4ms\tremaining: 204ms\n",
      "11:\ttotal: 63ms\tremaining: 199ms\n",
      "12:\ttotal: 68ms\tremaining: 194ms\n",
      "13:\ttotal: 73.4ms\tremaining: 189ms\n",
      "14:\ttotal: 78.6ms\tremaining: 183ms\n",
      "15:\ttotal: 83.8ms\tremaining: 178ms\n",
      "16:\ttotal: 89ms\tremaining: 173ms\n",
      "17:\ttotal: 94.3ms\tremaining: 168ms\n",
      "18:\ttotal: 99.6ms\tremaining: 163ms\n",
      "19:\ttotal: 105ms\tremaining: 157ms\n",
      "20:\ttotal: 110ms\tremaining: 152ms\n",
      "21:\ttotal: 116ms\tremaining: 147ms\n",
      "22:\ttotal: 121ms\tremaining: 142ms\n",
      "23:\ttotal: 126ms\tremaining: 137ms\n",
      "24:\ttotal: 131ms\tremaining: 131ms\n",
      "25:\ttotal: 136ms\tremaining: 126ms\n",
      "26:\ttotal: 141ms\tremaining: 120ms\n",
      "27:\ttotal: 146ms\tremaining: 115ms\n",
      "28:\ttotal: 152ms\tremaining: 110ms\n",
      "29:\ttotal: 157ms\tremaining: 105ms\n",
      "30:\ttotal: 162ms\tremaining: 99.3ms\n",
      "31:\ttotal: 167ms\tremaining: 94ms\n",
      "32:\ttotal: 172ms\tremaining: 88.6ms\n",
      "33:\ttotal: 177ms\tremaining: 83.5ms\n",
      "34:\ttotal: 184ms\tremaining: 78.8ms\n",
      "35:\ttotal: 189ms\tremaining: 73.7ms\n",
      "36:\ttotal: 195ms\tremaining: 68.5ms\n",
      "37:\ttotal: 200ms\tremaining: 63.2ms\n",
      "38:\ttotal: 205ms\tremaining: 57.8ms\n",
      "39:\ttotal: 210ms\tremaining: 52.6ms\n",
      "40:\ttotal: 215ms\tremaining: 47.3ms\n",
      "41:\ttotal: 221ms\tremaining: 42ms\n",
      "42:\ttotal: 226ms\tremaining: 36.7ms\n",
      "43:\ttotal: 231ms\tremaining: 31.5ms\n",
      "44:\ttotal: 236ms\tremaining: 26.3ms\n",
      "45:\ttotal: 242ms\tremaining: 21ms\n",
      "46:\ttotal: 247ms\tremaining: 15.8ms\n",
      "47:\ttotal: 252ms\tremaining: 10.5ms\n",
      "48:\ttotal: 257ms\tremaining: 5.25ms\n",
      "49:\ttotal: 263ms\tremaining: 0us\n",
      "0:\ttotal: 6.53ms\tremaining: 320ms\n",
      "1:\ttotal: 11.6ms\tremaining: 279ms\n",
      "2:\ttotal: 16.4ms\tremaining: 257ms\n",
      "3:\ttotal: 22.4ms\tremaining: 258ms\n",
      "4:\ttotal: 27.3ms\tremaining: 246ms\n",
      "5:\ttotal: 32.4ms\tremaining: 237ms\n",
      "6:\ttotal: 37.4ms\tremaining: 230ms\n",
      "7:\ttotal: 42.7ms\tremaining: 224ms\n",
      "8:\ttotal: 48ms\tremaining: 219ms\n",
      "9:\ttotal: 53.2ms\tremaining: 213ms\n",
      "10:\ttotal: 58.8ms\tremaining: 209ms\n",
      "11:\ttotal: 64.1ms\tremaining: 203ms\n",
      "12:\ttotal: 69.9ms\tremaining: 199ms\n",
      "13:\ttotal: 75.9ms\tremaining: 195ms\n",
      "14:\ttotal: 82.4ms\tremaining: 192ms\n",
      "15:\ttotal: 88.4ms\tremaining: 188ms\n",
      "16:\ttotal: 94ms\tremaining: 183ms\n",
      "17:\ttotal: 100ms\tremaining: 178ms\n",
      "18:\ttotal: 107ms\tremaining: 174ms\n",
      "19:\ttotal: 112ms\tremaining: 169ms\n",
      "20:\ttotal: 118ms\tremaining: 163ms\n",
      "21:\ttotal: 123ms\tremaining: 157ms\n",
      "22:\ttotal: 129ms\tremaining: 152ms\n",
      "23:\ttotal: 135ms\tremaining: 146ms\n",
      "24:\ttotal: 142ms\tremaining: 142ms\n",
      "25:\ttotal: 148ms\tremaining: 136ms\n",
      "26:\ttotal: 153ms\tremaining: 131ms\n",
      "27:\ttotal: 159ms\tremaining: 125ms\n",
      "28:\ttotal: 165ms\tremaining: 120ms\n",
      "29:\ttotal: 171ms\tremaining: 114ms\n",
      "30:\ttotal: 178ms\tremaining: 109ms\n",
      "31:\ttotal: 184ms\tremaining: 103ms\n",
      "32:\ttotal: 190ms\tremaining: 97.8ms\n",
      "33:\ttotal: 196ms\tremaining: 92.2ms\n",
      "34:\ttotal: 202ms\tremaining: 86.8ms\n",
      "35:\ttotal: 209ms\tremaining: 81.3ms\n",
      "36:\ttotal: 216ms\tremaining: 75.8ms\n",
      "37:\ttotal: 222ms\tremaining: 70.1ms\n",
      "38:\ttotal: 229ms\tremaining: 64.5ms\n",
      "39:\ttotal: 238ms\tremaining: 59.4ms\n",
      "40:\ttotal: 245ms\tremaining: 53.7ms\n",
      "41:\ttotal: 251ms\tremaining: 47.7ms\n",
      "42:\ttotal: 257ms\tremaining: 41.8ms\n",
      "43:\ttotal: 263ms\tremaining: 35.9ms\n",
      "44:\ttotal: 270ms\tremaining: 30ms\n",
      "45:\ttotal: 277ms\tremaining: 24.1ms\n",
      "46:\ttotal: 283ms\tremaining: 18.1ms\n",
      "47:\ttotal: 289ms\tremaining: 12.1ms\n",
      "48:\ttotal: 296ms\tremaining: 6.04ms\n",
      "49:\ttotal: 303ms\tremaining: 0us\n",
      "0:\ttotal: 10.5ms\tremaining: 514ms\n",
      "1:\ttotal: 15.5ms\tremaining: 373ms\n",
      "2:\ttotal: 20.3ms\tremaining: 318ms\n",
      "3:\ttotal: 25.1ms\tremaining: 289ms\n",
      "4:\ttotal: 29.9ms\tremaining: 269ms\n",
      "5:\ttotal: 34.8ms\tremaining: 255ms\n",
      "6:\ttotal: 40.6ms\tremaining: 249ms\n",
      "7:\ttotal: 45.5ms\tremaining: 239ms\n",
      "8:\ttotal: 52ms\tremaining: 237ms\n",
      "9:\ttotal: 57.4ms\tremaining: 230ms\n",
      "10:\ttotal: 62.6ms\tremaining: 222ms\n",
      "11:\ttotal: 67.7ms\tremaining: 214ms\n",
      "12:\ttotal: 72.8ms\tremaining: 207ms\n",
      "13:\ttotal: 77.8ms\tremaining: 200ms\n",
      "14:\ttotal: 82.9ms\tremaining: 193ms\n",
      "15:\ttotal: 88.5ms\tremaining: 188ms\n",
      "16:\ttotal: 93.9ms\tremaining: 182ms\n",
      "17:\ttotal: 99.6ms\tremaining: 177ms\n",
      "18:\ttotal: 106ms\tremaining: 173ms\n",
      "19:\ttotal: 112ms\tremaining: 168ms\n",
      "20:\ttotal: 117ms\tremaining: 162ms\n",
      "21:\ttotal: 123ms\tremaining: 156ms\n",
      "22:\ttotal: 128ms\tremaining: 151ms\n",
      "23:\ttotal: 134ms\tremaining: 145ms\n",
      "24:\ttotal: 139ms\tremaining: 139ms\n",
      "25:\ttotal: 145ms\tremaining: 134ms\n",
      "26:\ttotal: 151ms\tremaining: 128ms\n",
      "27:\ttotal: 156ms\tremaining: 123ms\n",
      "28:\ttotal: 162ms\tremaining: 118ms\n",
      "29:\ttotal: 168ms\tremaining: 112ms\n",
      "30:\ttotal: 175ms\tremaining: 107ms\n",
      "31:\ttotal: 180ms\tremaining: 102ms\n",
      "32:\ttotal: 187ms\tremaining: 96.2ms\n",
      "33:\ttotal: 193ms\tremaining: 90.8ms\n",
      "34:\ttotal: 199ms\tremaining: 85.1ms\n",
      "35:\ttotal: 204ms\tremaining: 79.4ms\n",
      "36:\ttotal: 210ms\tremaining: 73.7ms\n",
      "37:\ttotal: 216ms\tremaining: 68.1ms\n",
      "38:\ttotal: 221ms\tremaining: 62.5ms\n",
      "39:\ttotal: 228ms\tremaining: 56.9ms\n",
      "40:\ttotal: 233ms\tremaining: 51.2ms\n",
      "41:\ttotal: 239ms\tremaining: 45.6ms\n",
      "42:\ttotal: 245ms\tremaining: 40ms\n",
      "43:\ttotal: 252ms\tremaining: 34.3ms\n",
      "44:\ttotal: 258ms\tremaining: 28.7ms\n",
      "45:\ttotal: 264ms\tremaining: 23ms\n",
      "46:\ttotal: 270ms\tremaining: 17.2ms\n",
      "47:\ttotal: 276ms\tremaining: 11.5ms\n",
      "48:\ttotal: 282ms\tremaining: 5.76ms\n",
      "49:\ttotal: 288ms\tremaining: 0us\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttotal: 6.59ms\tremaining: 323ms\n",
      "1:\ttotal: 11.7ms\tremaining: 280ms\n",
      "2:\ttotal: 16.4ms\tremaining: 258ms\n",
      "3:\ttotal: 22.2ms\tremaining: 255ms\n",
      "4:\ttotal: 27.2ms\tremaining: 245ms\n",
      "5:\ttotal: 33ms\tremaining: 242ms\n",
      "6:\ttotal: 38.6ms\tremaining: 237ms\n",
      "7:\ttotal: 44.1ms\tremaining: 232ms\n",
      "8:\ttotal: 49.4ms\tremaining: 225ms\n",
      "9:\ttotal: 54.4ms\tremaining: 218ms\n",
      "10:\ttotal: 59.7ms\tremaining: 212ms\n",
      "11:\ttotal: 65.2ms\tremaining: 206ms\n",
      "12:\ttotal: 70.8ms\tremaining: 201ms\n",
      "13:\ttotal: 76.5ms\tremaining: 197ms\n",
      "14:\ttotal: 82.3ms\tremaining: 192ms\n",
      "15:\ttotal: 87.5ms\tremaining: 186ms\n",
      "16:\ttotal: 93ms\tremaining: 181ms\n",
      "17:\ttotal: 99.8ms\tremaining: 177ms\n",
      "18:\ttotal: 106ms\tremaining: 173ms\n",
      "19:\ttotal: 112ms\tremaining: 168ms\n",
      "20:\ttotal: 117ms\tremaining: 162ms\n",
      "21:\ttotal: 123ms\tremaining: 157ms\n",
      "22:\ttotal: 128ms\tremaining: 151ms\n",
      "23:\ttotal: 134ms\tremaining: 145ms\n",
      "24:\ttotal: 139ms\tremaining: 139ms\n",
      "25:\ttotal: 145ms\tremaining: 134ms\n",
      "26:\ttotal: 151ms\tremaining: 128ms\n",
      "27:\ttotal: 156ms\tremaining: 123ms\n",
      "28:\ttotal: 162ms\tremaining: 117ms\n",
      "29:\ttotal: 168ms\tremaining: 112ms\n",
      "30:\ttotal: 173ms\tremaining: 106ms\n",
      "31:\ttotal: 179ms\tremaining: 101ms\n",
      "32:\ttotal: 185ms\tremaining: 95.6ms\n",
      "33:\ttotal: 191ms\tremaining: 89.9ms\n",
      "34:\ttotal: 197ms\tremaining: 84.3ms\n",
      "35:\ttotal: 203ms\tremaining: 78.8ms\n",
      "36:\ttotal: 209ms\tremaining: 73.5ms\n",
      "37:\ttotal: 215ms\tremaining: 68ms\n",
      "38:\ttotal: 221ms\tremaining: 62.4ms\n",
      "39:\ttotal: 227ms\tremaining: 56.8ms\n",
      "40:\ttotal: 233ms\tremaining: 51.1ms\n",
      "41:\ttotal: 239ms\tremaining: 45.5ms\n",
      "42:\ttotal: 245ms\tremaining: 39.9ms\n",
      "43:\ttotal: 251ms\tremaining: 34.3ms\n",
      "44:\ttotal: 258ms\tremaining: 28.6ms\n",
      "45:\ttotal: 265ms\tremaining: 23ms\n",
      "46:\ttotal: 270ms\tremaining: 17.3ms\n",
      "47:\ttotal: 276ms\tremaining: 11.5ms\n",
      "48:\ttotal: 282ms\tremaining: 5.76ms\n",
      "49:\ttotal: 288ms\tremaining: 0us\n",
      "0:\ttotal: 21ms\tremaining: 1.03s\n",
      "1:\ttotal: 35.1ms\tremaining: 842ms\n",
      "2:\ttotal: 44.5ms\tremaining: 698ms\n",
      "3:\ttotal: 52.4ms\tremaining: 603ms\n",
      "4:\ttotal: 58.9ms\tremaining: 530ms\n",
      "5:\ttotal: 65.5ms\tremaining: 480ms\n",
      "6:\ttotal: 71ms\tremaining: 436ms\n",
      "7:\ttotal: 76.4ms\tremaining: 401ms\n",
      "8:\ttotal: 83.2ms\tremaining: 379ms\n",
      "9:\ttotal: 88.8ms\tremaining: 355ms\n",
      "10:\ttotal: 94.9ms\tremaining: 336ms\n",
      "11:\ttotal: 100ms\tremaining: 318ms\n",
      "12:\ttotal: 106ms\tremaining: 301ms\n",
      "13:\ttotal: 112ms\tremaining: 287ms\n",
      "14:\ttotal: 117ms\tremaining: 273ms\n",
      "15:\ttotal: 123ms\tremaining: 261ms\n",
      "16:\ttotal: 128ms\tremaining: 249ms\n",
      "17:\ttotal: 134ms\tremaining: 238ms\n",
      "18:\ttotal: 141ms\tremaining: 230ms\n",
      "19:\ttotal: 147ms\tremaining: 221ms\n",
      "20:\ttotal: 153ms\tremaining: 211ms\n",
      "21:\ttotal: 159ms\tremaining: 203ms\n",
      "22:\ttotal: 165ms\tremaining: 194ms\n",
      "23:\ttotal: 171ms\tremaining: 185ms\n",
      "24:\ttotal: 177ms\tremaining: 177ms\n",
      "25:\ttotal: 183ms\tremaining: 169ms\n",
      "26:\ttotal: 189ms\tremaining: 161ms\n",
      "27:\ttotal: 195ms\tremaining: 153ms\n",
      "28:\ttotal: 202ms\tremaining: 146ms\n",
      "29:\ttotal: 208ms\tremaining: 138ms\n",
      "30:\ttotal: 214ms\tremaining: 131ms\n",
      "31:\ttotal: 221ms\tremaining: 124ms\n",
      "32:\ttotal: 227ms\tremaining: 117ms\n",
      "33:\ttotal: 234ms\tremaining: 110ms\n",
      "34:\ttotal: 241ms\tremaining: 103ms\n",
      "35:\ttotal: 247ms\tremaining: 96.1ms\n",
      "36:\ttotal: 253ms\tremaining: 88.9ms\n",
      "37:\ttotal: 261ms\tremaining: 82.3ms\n",
      "38:\ttotal: 266ms\tremaining: 75.2ms\n",
      "39:\ttotal: 274ms\tremaining: 68.5ms\n",
      "40:\ttotal: 280ms\tremaining: 61.5ms\n",
      "41:\ttotal: 287ms\tremaining: 54.6ms\n",
      "42:\ttotal: 293ms\tremaining: 47.7ms\n",
      "43:\ttotal: 300ms\tremaining: 40.9ms\n",
      "44:\ttotal: 306ms\tremaining: 34ms\n",
      "45:\ttotal: 313ms\tremaining: 27.2ms\n",
      "46:\ttotal: 319ms\tremaining: 20.3ms\n",
      "47:\ttotal: 327ms\tremaining: 13.6ms\n",
      "48:\ttotal: 333ms\tremaining: 6.79ms\n",
      "49:\ttotal: 339ms\tremaining: 0us\n",
      "0:\ttotal: 9.28ms\tremaining: 455ms\n",
      "1:\ttotal: 14.9ms\tremaining: 358ms\n",
      "2:\ttotal: 20.1ms\tremaining: 315ms\n",
      "3:\ttotal: 24.9ms\tremaining: 287ms\n",
      "4:\ttotal: 30.9ms\tremaining: 278ms\n",
      "5:\ttotal: 35.8ms\tremaining: 263ms\n",
      "6:\ttotal: 40.8ms\tremaining: 251ms\n",
      "7:\ttotal: 45.8ms\tremaining: 240ms\n",
      "8:\ttotal: 51.3ms\tremaining: 234ms\n",
      "9:\ttotal: 56.5ms\tremaining: 226ms\n",
      "10:\ttotal: 61.5ms\tremaining: 218ms\n",
      "11:\ttotal: 66.8ms\tremaining: 212ms\n",
      "12:\ttotal: 72ms\tremaining: 205ms\n",
      "13:\ttotal: 77.1ms\tremaining: 198ms\n",
      "14:\ttotal: 82.9ms\tremaining: 193ms\n",
      "15:\ttotal: 88.9ms\tremaining: 189ms\n",
      "16:\ttotal: 94ms\tremaining: 183ms\n",
      "17:\ttotal: 99.7ms\tremaining: 177ms\n",
      "18:\ttotal: 105ms\tremaining: 171ms\n",
      "19:\ttotal: 110ms\tremaining: 166ms\n",
      "20:\ttotal: 116ms\tremaining: 160ms\n",
      "21:\ttotal: 122ms\tremaining: 155ms\n",
      "22:\ttotal: 127ms\tremaining: 149ms\n",
      "23:\ttotal: 134ms\tremaining: 145ms\n",
      "24:\ttotal: 139ms\tremaining: 139ms\n",
      "25:\ttotal: 145ms\tremaining: 134ms\n",
      "26:\ttotal: 150ms\tremaining: 128ms\n",
      "27:\ttotal: 156ms\tremaining: 123ms\n",
      "28:\ttotal: 162ms\tremaining: 117ms\n",
      "29:\ttotal: 167ms\tremaining: 112ms\n",
      "30:\ttotal: 173ms\tremaining: 106ms\n",
      "31:\ttotal: 179ms\tremaining: 101ms\n",
      "32:\ttotal: 187ms\tremaining: 96.3ms\n",
      "33:\ttotal: 193ms\tremaining: 90.7ms\n",
      "34:\ttotal: 199ms\tremaining: 85.3ms\n",
      "35:\ttotal: 205ms\tremaining: 79.7ms\n",
      "36:\ttotal: 211ms\tremaining: 74.1ms\n",
      "37:\ttotal: 217ms\tremaining: 68.5ms\n",
      "38:\ttotal: 223ms\tremaining: 62.9ms\n",
      "39:\ttotal: 229ms\tremaining: 57.2ms\n",
      "40:\ttotal: 236ms\tremaining: 51.9ms\n",
      "41:\ttotal: 243ms\tremaining: 46.2ms\n",
      "42:\ttotal: 249ms\tremaining: 40.5ms\n",
      "43:\ttotal: 255ms\tremaining: 34.8ms\n",
      "44:\ttotal: 261ms\tremaining: 29ms\n",
      "45:\ttotal: 267ms\tremaining: 23.2ms\n",
      "46:\ttotal: 273ms\tremaining: 17.4ms\n",
      "47:\ttotal: 279ms\tremaining: 11.6ms\n",
      "48:\ttotal: 285ms\tremaining: 5.83ms\n",
      "49:\ttotal: 292ms\tremaining: 0us\n",
      "0:\ttotal: 5.39ms\tremaining: 264ms\n",
      "1:\ttotal: 10.6ms\tremaining: 254ms\n",
      "2:\ttotal: 15.2ms\tremaining: 239ms\n",
      "3:\ttotal: 19.9ms\tremaining: 229ms\n",
      "4:\ttotal: 24.8ms\tremaining: 223ms\n",
      "5:\ttotal: 29.8ms\tremaining: 218ms\n",
      "6:\ttotal: 35.8ms\tremaining: 220ms\n",
      "7:\ttotal: 40.9ms\tremaining: 214ms\n",
      "8:\ttotal: 46ms\tremaining: 209ms\n",
      "9:\ttotal: 50.8ms\tremaining: 203ms\n",
      "10:\ttotal: 56.1ms\tremaining: 199ms\n",
      "11:\ttotal: 61ms\tremaining: 193ms\n",
      "12:\ttotal: 66.3ms\tremaining: 189ms\n",
      "13:\ttotal: 72.7ms\tremaining: 187ms\n",
      "14:\ttotal: 78.2ms\tremaining: 182ms\n",
      "15:\ttotal: 83.8ms\tremaining: 178ms\n",
      "16:\ttotal: 89.4ms\tremaining: 173ms\n",
      "17:\ttotal: 95ms\tremaining: 169ms\n",
      "18:\ttotal: 101ms\tremaining: 164ms\n",
      "19:\ttotal: 106ms\tremaining: 159ms\n",
      "20:\ttotal: 111ms\tremaining: 154ms\n",
      "21:\ttotal: 117ms\tremaining: 149ms\n",
      "22:\ttotal: 122ms\tremaining: 144ms\n",
      "23:\ttotal: 128ms\tremaining: 139ms\n",
      "24:\ttotal: 133ms\tremaining: 133ms\n",
      "25:\ttotal: 139ms\tremaining: 128ms\n",
      "26:\ttotal: 145ms\tremaining: 123ms\n",
      "27:\ttotal: 150ms\tremaining: 118ms\n",
      "28:\ttotal: 156ms\tremaining: 113ms\n",
      "29:\ttotal: 161ms\tremaining: 108ms\n",
      "30:\ttotal: 167ms\tremaining: 103ms\n",
      "31:\ttotal: 173ms\tremaining: 97.4ms\n",
      "32:\ttotal: 178ms\tremaining: 91.9ms\n",
      "33:\ttotal: 184ms\tremaining: 86.7ms\n",
      "34:\ttotal: 190ms\tremaining: 81.5ms\n",
      "35:\ttotal: 196ms\tremaining: 76.2ms\n",
      "36:\ttotal: 202ms\tremaining: 71ms\n",
      "37:\ttotal: 208ms\tremaining: 65.6ms\n",
      "38:\ttotal: 214ms\tremaining: 60.3ms\n",
      "39:\ttotal: 219ms\tremaining: 54.9ms\n",
      "40:\ttotal: 225ms\tremaining: 49.5ms\n",
      "41:\ttotal: 231ms\tremaining: 44ms\n",
      "42:\ttotal: 238ms\tremaining: 38.7ms\n",
      "43:\ttotal: 243ms\tremaining: 33.2ms\n",
      "44:\ttotal: 249ms\tremaining: 27.7ms\n",
      "45:\ttotal: 255ms\tremaining: 22.2ms\n",
      "46:\ttotal: 261ms\tremaining: 16.7ms\n",
      "47:\ttotal: 268ms\tremaining: 11.2ms\n",
      "48:\ttotal: 274ms\tremaining: 5.58ms\n",
      "49:\ttotal: 280ms\tremaining: 0us\n",
      "0:\ttotal: 5.92ms\tremaining: 290ms\n",
      "1:\ttotal: 11.1ms\tremaining: 266ms\n",
      "2:\ttotal: 15.6ms\tremaining: 245ms\n",
      "3:\ttotal: 20.7ms\tremaining: 238ms\n",
      "4:\ttotal: 25.5ms\tremaining: 230ms\n",
      "5:\ttotal: 30.8ms\tremaining: 226ms\n",
      "6:\ttotal: 36.4ms\tremaining: 223ms\n",
      "7:\ttotal: 41.7ms\tremaining: 219ms\n",
      "8:\ttotal: 46.6ms\tremaining: 212ms\n",
      "9:\ttotal: 51.5ms\tremaining: 206ms\n",
      "10:\ttotal: 57.1ms\tremaining: 203ms\n",
      "11:\ttotal: 62.2ms\tremaining: 197ms\n",
      "12:\ttotal: 67.3ms\tremaining: 191ms\n",
      "13:\ttotal: 73ms\tremaining: 188ms\n",
      "14:\ttotal: 78.4ms\tremaining: 183ms\n",
      "15:\ttotal: 83.9ms\tremaining: 178ms\n",
      "16:\ttotal: 89.8ms\tremaining: 174ms\n",
      "17:\ttotal: 95.6ms\tremaining: 170ms\n",
      "18:\ttotal: 101ms\tremaining: 165ms\n",
      "19:\ttotal: 107ms\tremaining: 160ms\n",
      "20:\ttotal: 112ms\tremaining: 155ms\n",
      "21:\ttotal: 118ms\tremaining: 150ms\n",
      "22:\ttotal: 124ms\tremaining: 145ms\n",
      "23:\ttotal: 129ms\tremaining: 140ms\n",
      "24:\ttotal: 135ms\tremaining: 135ms\n",
      "25:\ttotal: 140ms\tremaining: 130ms\n",
      "26:\ttotal: 146ms\tremaining: 125ms\n",
      "27:\ttotal: 152ms\tremaining: 119ms\n",
      "28:\ttotal: 158ms\tremaining: 114ms\n",
      "29:\ttotal: 165ms\tremaining: 110ms\n",
      "30:\ttotal: 171ms\tremaining: 105ms\n",
      "31:\ttotal: 177ms\tremaining: 99.3ms\n",
      "32:\ttotal: 182ms\tremaining: 94ms\n",
      "33:\ttotal: 188ms\tremaining: 88.5ms\n",
      "34:\ttotal: 195ms\tremaining: 83.4ms\n",
      "35:\ttotal: 201ms\tremaining: 78.1ms\n",
      "36:\ttotal: 207ms\tremaining: 72.6ms\n",
      "37:\ttotal: 212ms\tremaining: 66.9ms\n",
      "38:\ttotal: 218ms\tremaining: 61.4ms\n",
      "39:\ttotal: 224ms\tremaining: 56ms\n",
      "40:\ttotal: 230ms\tremaining: 50.5ms\n",
      "41:\ttotal: 236ms\tremaining: 44.9ms\n",
      "42:\ttotal: 241ms\tremaining: 39.3ms\n",
      "43:\ttotal: 247ms\tremaining: 33.7ms\n",
      "44:\ttotal: 254ms\tremaining: 28.2ms\n",
      "45:\ttotal: 260ms\tremaining: 22.6ms\n",
      "46:\ttotal: 268ms\tremaining: 17.1ms\n",
      "47:\ttotal: 274ms\tremaining: 11.4ms\n",
      "48:\ttotal: 279ms\tremaining: 5.7ms\n",
      "49:\ttotal: 285ms\tremaining: 0us\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttotal: 5.99ms\tremaining: 293ms\n",
      "1:\ttotal: 11.6ms\tremaining: 278ms\n",
      "2:\ttotal: 16.3ms\tremaining: 255ms\n",
      "3:\ttotal: 21.4ms\tremaining: 246ms\n",
      "4:\ttotal: 26.6ms\tremaining: 239ms\n",
      "5:\ttotal: 31.7ms\tremaining: 232ms\n",
      "6:\ttotal: 36.6ms\tremaining: 225ms\n",
      "7:\ttotal: 41.4ms\tremaining: 217ms\n",
      "8:\ttotal: 46.8ms\tremaining: 213ms\n",
      "9:\ttotal: 52.2ms\tremaining: 209ms\n",
      "10:\ttotal: 57.6ms\tremaining: 204ms\n",
      "11:\ttotal: 63.3ms\tremaining: 200ms\n",
      "12:\ttotal: 69.1ms\tremaining: 197ms\n",
      "13:\ttotal: 74.5ms\tremaining: 192ms\n",
      "14:\ttotal: 79.8ms\tremaining: 186ms\n",
      "15:\ttotal: 85.1ms\tremaining: 181ms\n",
      "16:\ttotal: 90.5ms\tremaining: 176ms\n",
      "17:\ttotal: 95.9ms\tremaining: 170ms\n",
      "18:\ttotal: 102ms\tremaining: 167ms\n",
      "19:\ttotal: 108ms\tremaining: 162ms\n",
      "20:\ttotal: 114ms\tremaining: 157ms\n",
      "21:\ttotal: 119ms\tremaining: 152ms\n",
      "22:\ttotal: 125ms\tremaining: 146ms\n",
      "23:\ttotal: 130ms\tremaining: 141ms\n",
      "24:\ttotal: 136ms\tremaining: 136ms\n",
      "25:\ttotal: 141ms\tremaining: 130ms\n",
      "26:\ttotal: 148ms\tremaining: 126ms\n",
      "27:\ttotal: 154ms\tremaining: 121ms\n",
      "28:\ttotal: 160ms\tremaining: 116ms\n",
      "29:\ttotal: 165ms\tremaining: 110ms\n",
      "30:\ttotal: 171ms\tremaining: 105ms\n",
      "31:\ttotal: 177ms\tremaining: 99.5ms\n",
      "32:\ttotal: 184ms\tremaining: 94.7ms\n",
      "33:\ttotal: 191ms\tremaining: 90ms\n",
      "34:\ttotal: 197ms\tremaining: 84.6ms\n",
      "35:\ttotal: 204ms\tremaining: 79.2ms\n",
      "36:\ttotal: 210ms\tremaining: 73.7ms\n",
      "37:\ttotal: 216ms\tremaining: 68.2ms\n",
      "38:\ttotal: 222ms\tremaining: 62.6ms\n",
      "39:\ttotal: 228ms\tremaining: 56.9ms\n",
      "40:\ttotal: 234ms\tremaining: 51.4ms\n",
      "41:\ttotal: 240ms\tremaining: 45.8ms\n",
      "42:\ttotal: 246ms\tremaining: 40.1ms\n",
      "43:\ttotal: 253ms\tremaining: 34.5ms\n",
      "44:\ttotal: 259ms\tremaining: 28.8ms\n",
      "45:\ttotal: 265ms\tremaining: 23.1ms\n",
      "46:\ttotal: 273ms\tremaining: 17.4ms\n",
      "47:\ttotal: 279ms\tremaining: 11.6ms\n",
      "48:\ttotal: 286ms\tremaining: 5.84ms\n",
      "49:\ttotal: 293ms\tremaining: 0us\n",
      "0:\ttotal: 5.8ms\tremaining: 284ms\n",
      "1:\ttotal: 10.6ms\tremaining: 254ms\n",
      "2:\ttotal: 15.6ms\tremaining: 244ms\n",
      "3:\ttotal: 20.7ms\tremaining: 238ms\n",
      "4:\ttotal: 25.5ms\tremaining: 229ms\n",
      "5:\ttotal: 30.6ms\tremaining: 224ms\n",
      "6:\ttotal: 35.7ms\tremaining: 219ms\n",
      "7:\ttotal: 41.1ms\tremaining: 216ms\n",
      "8:\ttotal: 46.1ms\tremaining: 210ms\n",
      "9:\ttotal: 51.5ms\tremaining: 206ms\n",
      "10:\ttotal: 56.7ms\tremaining: 201ms\n",
      "11:\ttotal: 61.8ms\tremaining: 196ms\n",
      "12:\ttotal: 67ms\tremaining: 191ms\n",
      "13:\ttotal: 72.5ms\tremaining: 186ms\n",
      "14:\ttotal: 77.7ms\tremaining: 181ms\n",
      "15:\ttotal: 83.2ms\tremaining: 177ms\n",
      "16:\ttotal: 88.6ms\tremaining: 172ms\n",
      "17:\ttotal: 96.3ms\tremaining: 171ms\n",
      "18:\ttotal: 104ms\tremaining: 169ms\n",
      "19:\ttotal: 110ms\tremaining: 165ms\n",
      "20:\ttotal: 116ms\tremaining: 160ms\n",
      "21:\ttotal: 122ms\tremaining: 155ms\n",
      "22:\ttotal: 128ms\tremaining: 150ms\n",
      "23:\ttotal: 134ms\tremaining: 145ms\n",
      "24:\ttotal: 140ms\tremaining: 140ms\n",
      "25:\ttotal: 146ms\tremaining: 135ms\n",
      "26:\ttotal: 153ms\tremaining: 130ms\n",
      "27:\ttotal: 159ms\tremaining: 125ms\n",
      "28:\ttotal: 167ms\tremaining: 121ms\n",
      "29:\ttotal: 174ms\tremaining: 116ms\n",
      "30:\ttotal: 180ms\tremaining: 110ms\n",
      "31:\ttotal: 186ms\tremaining: 105ms\n",
      "32:\ttotal: 192ms\tremaining: 98.9ms\n",
      "33:\ttotal: 198ms\tremaining: 93.3ms\n",
      "34:\ttotal: 204ms\tremaining: 87.6ms\n",
      "35:\ttotal: 211ms\tremaining: 82ms\n",
      "36:\ttotal: 217ms\tremaining: 76.4ms\n",
      "37:\ttotal: 228ms\tremaining: 71.9ms\n",
      "38:\ttotal: 234ms\tremaining: 66.1ms\n",
      "39:\ttotal: 243ms\tremaining: 60.7ms\n",
      "40:\ttotal: 249ms\tremaining: 54.8ms\n",
      "41:\ttotal: 259ms\tremaining: 49.3ms\n",
      "42:\ttotal: 266ms\tremaining: 43.3ms\n",
      "43:\ttotal: 274ms\tremaining: 37.3ms\n",
      "44:\ttotal: 281ms\tremaining: 31.2ms\n",
      "45:\ttotal: 290ms\tremaining: 25.2ms\n",
      "46:\ttotal: 298ms\tremaining: 19ms\n",
      "47:\ttotal: 305ms\tremaining: 12.7ms\n",
      "48:\ttotal: 313ms\tremaining: 6.38ms\n",
      "49:\ttotal: 320ms\tremaining: 0us\n",
      "0:\ttotal: 9.1ms\tremaining: 446ms\n",
      "1:\ttotal: 14.4ms\tremaining: 347ms\n",
      "2:\ttotal: 19.6ms\tremaining: 306ms\n",
      "3:\ttotal: 25.1ms\tremaining: 289ms\n",
      "4:\ttotal: 30.3ms\tremaining: 273ms\n",
      "5:\ttotal: 35.9ms\tremaining: 263ms\n",
      "6:\ttotal: 41.3ms\tremaining: 253ms\n",
      "7:\ttotal: 47.4ms\tremaining: 249ms\n",
      "8:\ttotal: 53ms\tremaining: 241ms\n",
      "9:\ttotal: 58.8ms\tremaining: 235ms\n",
      "10:\ttotal: 63.9ms\tremaining: 227ms\n",
      "11:\ttotal: 69.2ms\tremaining: 219ms\n",
      "12:\ttotal: 75ms\tremaining: 214ms\n",
      "13:\ttotal: 80.4ms\tremaining: 207ms\n",
      "14:\ttotal: 86.9ms\tremaining: 203ms\n",
      "15:\ttotal: 92.6ms\tremaining: 197ms\n",
      "16:\ttotal: 98.6ms\tremaining: 191ms\n",
      "17:\ttotal: 105ms\tremaining: 187ms\n",
      "18:\ttotal: 111ms\tremaining: 182ms\n",
      "19:\ttotal: 117ms\tremaining: 176ms\n",
      "20:\ttotal: 123ms\tremaining: 170ms\n",
      "21:\ttotal: 128ms\tremaining: 163ms\n",
      "22:\ttotal: 134ms\tremaining: 157ms\n",
      "23:\ttotal: 139ms\tremaining: 151ms\n",
      "24:\ttotal: 146ms\tremaining: 146ms\n",
      "25:\ttotal: 152ms\tremaining: 140ms\n",
      "26:\ttotal: 158ms\tremaining: 135ms\n",
      "27:\ttotal: 165ms\tremaining: 130ms\n",
      "28:\ttotal: 171ms\tremaining: 124ms\n",
      "29:\ttotal: 177ms\tremaining: 118ms\n",
      "30:\ttotal: 183ms\tremaining: 112ms\n",
      "31:\ttotal: 189ms\tremaining: 106ms\n",
      "32:\ttotal: 195ms\tremaining: 100ms\n",
      "33:\ttotal: 201ms\tremaining: 94.7ms\n",
      "34:\ttotal: 208ms\tremaining: 89ms\n",
      "35:\ttotal: 213ms\tremaining: 83ms\n",
      "36:\ttotal: 219ms\tremaining: 77.1ms\n",
      "37:\ttotal: 226ms\tremaining: 71.3ms\n",
      "38:\ttotal: 232ms\tremaining: 65.4ms\n",
      "39:\ttotal: 238ms\tremaining: 59.6ms\n",
      "40:\ttotal: 244ms\tremaining: 53.6ms\n",
      "41:\ttotal: 252ms\tremaining: 48ms\n",
      "42:\ttotal: 259ms\tremaining: 42.1ms\n",
      "43:\ttotal: 265ms\tremaining: 36.1ms\n",
      "44:\ttotal: 271ms\tremaining: 30.1ms\n",
      "45:\ttotal: 277ms\tremaining: 24.1ms\n",
      "46:\ttotal: 283ms\tremaining: 18.1ms\n",
      "47:\ttotal: 290ms\tremaining: 12.1ms\n",
      "48:\ttotal: 298ms\tremaining: 6.08ms\n",
      "49:\ttotal: 304ms\tremaining: 0us\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n"
     ]
    }
   ],
   "source": [
    "# executing the basic models \n",
    "\n",
    "# executing logistic regression\n",
    "model_reglog = me.execute_model(LogisticRegression(random_state=123), \\\n",
    "                             pre_processador, 'Logistic_Regression', X_train, y_train, X_test, y_test)\n",
    "\n",
    "# executing Support Vector Machine\n",
    "model_svm = me.execute_model(SVC(kernel='rbf', probability=True, random_state=123), pre_processador, 'Support_Vector_Mac', \\\n",
    "                             X_train, y_train, X_test, y_test)\n",
    "\n",
    "# executing Mixed Gaussian Naive Bayes\n",
    "model_gnb = me.execute_model(MixedNB(), pre_processador, 'Gaussian_NB', X_train, y_train, X_test, y_test)\n",
    "\n",
    "# executing Decision Tree\n",
    "model_dt = me.execute_model(DecisionTreeClassifier(random_state=123), pre_processador, 'Decision_Tree', \\\n",
    "                            X_train, y_train, X_test, y_test)\n",
    "\n",
    "# executing Random Forest\n",
    "model_ranfor = me.execute_model(RandomForestClassifier(random_state=123), pre_processador, 'Random_Forest',\\\n",
    "                            X_train, y_train, X_test, y_test)\n",
    "\n",
    "# executing AdaBoost\n",
    "model_adb = me.execute_model(AdaBoostClassifier(n_estimators=50, algorithm='SAMME.R', learning_rate=0.8, random_state=123), \\\n",
    "                             pre_processador, 'AdaBoost', X_train, y_train, X_test, y_test)\n",
    "\n",
    "# executing Extra Trees\n",
    "model_xtr = me.execute_model(ExtraTreesClassifier(n_estimators=50, random_state=123), pre_processador, 'Extra_Trees',\\\n",
    "                             X_train, y_train, X_test, y_test)\n",
    "\n",
    "# executing Multi layer perceptron\n",
    "model_MLPerp = me.execute_model(MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1), \\\n",
    "                          pre_processador, 'MLPerceptron', X_train, y_train, X_test, y_test)\n",
    "\n",
    "# executing XGBoost\n",
    "model_XGBoos = me.execute_model(XGBClassifier(), pre_processador, 'XGBoost', X_train, y_train, X_test, y_test)\n",
    "\n",
    "# executing CatBoost\n",
    "model_cast = me.execute_model(CatBoostClassifier(iterations=50,\n",
    "                             learning_rate=0.02,\n",
    "                             depth=3,\n",
    "                             eval_metric='AUC',\n",
    "                             random_seed = 123,\n",
    "                             bagging_temperature = 0.2,\n",
    "                             od_type='Iter',\n",
    "                             od_wait=100), pre_processador, 'CatBoost', X_train, y_train, X_test, y_test)\n",
    "\n",
    "# executing Light GBM Boos\n",
    "model_lgb = me.execute_model(lgb.LGBMClassifier(num_iterations=50,\n",
    "                                             num_leaves=5,\n",
    "                                             min_data_in_leaf=1,\n",
    "                                             max_depth=3,\n",
    "                                             bagging_fraction=0.2,\n",
    "                                             max_bin=3,\n",
    "                                             random_state=123), pre_processador, 'lgbBoost', \n",
    "                             X_train, y_train, X_test, y_test ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Score_Train</th>\n",
       "      <th>Score_Test</th>\n",
       "      <th>Auc_Roc</th>\n",
       "      <th>Log_loss_Train</th>\n",
       "      <th>Log_loss_Test</th>\n",
       "      <th>Mean_Acc_Score</th>\n",
       "      <th>Std_Acc_Score</th>\n",
       "      <th>Model_Run</th>\n",
       "      <th>Diff_log_loss</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MLPerceptron</td>\n",
       "      <td>82.00</td>\n",
       "      <td>82.18</td>\n",
       "      <td>77.60</td>\n",
       "      <td>0.431045</td>\n",
       "      <td>0.428954</td>\n",
       "      <td>81.93</td>\n",
       "      <td>0.63</td>\n",
       "      <td>(ColumnTransformer(transformers=[('min_max_sca...</td>\n",
       "      <td>-0.002091</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic_Regression</td>\n",
       "      <td>82.02</td>\n",
       "      <td>82.15</td>\n",
       "      <td>76.73</td>\n",
       "      <td>0.438033</td>\n",
       "      <td>0.437253</td>\n",
       "      <td>81.98</td>\n",
       "      <td>0.68</td>\n",
       "      <td>(ColumnTransformer(transformers=[('min_max_sca...</td>\n",
       "      <td>-0.000780</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>88.37</td>\n",
       "      <td>81.42</td>\n",
       "      <td>94.45</td>\n",
       "      <td>0.280217</td>\n",
       "      <td>0.444547</td>\n",
       "      <td>81.39</td>\n",
       "      <td>0.77</td>\n",
       "      <td>(ColumnTransformer(transformers=[('min_max_sca...</td>\n",
       "      <td>0.164330</td>\n",
       "      <td>Overfit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random_Forest</td>\n",
       "      <td>99.94</td>\n",
       "      <td>82.20</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.113638</td>\n",
       "      <td>0.445196</td>\n",
       "      <td>81.39</td>\n",
       "      <td>0.59</td>\n",
       "      <td>(ColumnTransformer(transformers=[('min_max_sca...</td>\n",
       "      <td>0.331559</td>\n",
       "      <td>Overfit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>lgbBoost</td>\n",
       "      <td>80.10</td>\n",
       "      <td>80.62</td>\n",
       "      <td>75.24</td>\n",
       "      <td>0.453577</td>\n",
       "      <td>0.446746</td>\n",
       "      <td>80.06</td>\n",
       "      <td>0.52</td>\n",
       "      <td>(ColumnTransformer(transformers=[('min_max_sca...</td>\n",
       "      <td>-0.006831</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Support_Vector_Mac</td>\n",
       "      <td>82.01</td>\n",
       "      <td>82.02</td>\n",
       "      <td>75.77</td>\n",
       "      <td>0.447135</td>\n",
       "      <td>0.448496</td>\n",
       "      <td>81.80</td>\n",
       "      <td>0.54</td>\n",
       "      <td>(ColumnTransformer(transformers=[('min_max_sca...</td>\n",
       "      <td>0.001361</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>81.95</td>\n",
       "      <td>82.00</td>\n",
       "      <td>76.61</td>\n",
       "      <td>0.470352</td>\n",
       "      <td>0.467904</td>\n",
       "      <td>81.92</td>\n",
       "      <td>0.61</td>\n",
       "      <td>(ColumnTransformer(transformers=[('min_max_sca...</td>\n",
       "      <td>-0.002448</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Extra_Trees</td>\n",
       "      <td>99.94</td>\n",
       "      <td>81.25</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.000888</td>\n",
       "      <td>0.565823</td>\n",
       "      <td>80.50</td>\n",
       "      <td>0.74</td>\n",
       "      <td>(ColumnTransformer(transformers=[('min_max_sca...</td>\n",
       "      <td>0.564935</td>\n",
       "      <td>Overfit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>81.88</td>\n",
       "      <td>82.07</td>\n",
       "      <td>78.31</td>\n",
       "      <td>0.677516</td>\n",
       "      <td>0.677522</td>\n",
       "      <td>81.73</td>\n",
       "      <td>0.69</td>\n",
       "      <td>(ColumnTransformer(transformers=[('min_max_sca...</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gaussian_NB</td>\n",
       "      <td>76.51</td>\n",
       "      <td>77.40</td>\n",
       "      <td>67.00</td>\n",
       "      <td>1.180029</td>\n",
       "      <td>1.611133</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(ColumnTransformer(transformers=[('min_max_sca...</td>\n",
       "      <td>0.431105</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision_Tree</td>\n",
       "      <td>99.94</td>\n",
       "      <td>72.82</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.000888</td>\n",
       "      <td>9.377971</td>\n",
       "      <td>72.53</td>\n",
       "      <td>0.91</td>\n",
       "      <td>(ColumnTransformer(transformers=[('min_max_sca...</td>\n",
       "      <td>9.377083</td>\n",
       "      <td>Overfit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model  Score_Train  Score_Test  Auc_Roc  Log_loss_Train  \\\n",
       "7          MLPerceptron        82.00       82.18    77.60        0.431045   \n",
       "0   Logistic_Regression        82.02       82.15    76.73        0.438033   \n",
       "8               XGBoost        88.37       81.42    94.45        0.280217   \n",
       "4         Random_Forest        99.94       82.20   100.00        0.113638   \n",
       "10             lgbBoost        80.10       80.62    75.24        0.453577   \n",
       "1    Support_Vector_Mac        82.01       82.02    75.77        0.447135   \n",
       "9              CatBoost        81.95       82.00    76.61        0.470352   \n",
       "6           Extra_Trees        99.94       81.25   100.00        0.000888   \n",
       "5              AdaBoost        81.88       82.07    78.31        0.677516   \n",
       "2           Gaussian_NB        76.51       77.40    67.00        1.180029   \n",
       "3         Decision_Tree        99.94       72.82   100.00        0.000888   \n",
       "\n",
       "    Log_loss_Test  Mean_Acc_Score  Std_Acc_Score  \\\n",
       "7        0.428954           81.93           0.63   \n",
       "0        0.437253           81.98           0.68   \n",
       "8        0.444547           81.39           0.77   \n",
       "4        0.445196           81.39           0.59   \n",
       "10       0.446746           80.06           0.52   \n",
       "1        0.448496           81.80           0.54   \n",
       "9        0.467904           81.92           0.61   \n",
       "6        0.565823           80.50           0.74   \n",
       "5        0.677522           81.73           0.69   \n",
       "2        1.611133             NaN            NaN   \n",
       "3        9.377971           72.53           0.91   \n",
       "\n",
       "                                            Model_Run  Diff_log_loss   Status  \n",
       "7   (ColumnTransformer(transformers=[('min_max_sca...      -0.002091   Normal  \n",
       "0   (ColumnTransformer(transformers=[('min_max_sca...      -0.000780   Normal  \n",
       "8   (ColumnTransformer(transformers=[('min_max_sca...       0.164330  Overfit  \n",
       "4   (ColumnTransformer(transformers=[('min_max_sca...       0.331559  Overfit  \n",
       "10  (ColumnTransformer(transformers=[('min_max_sca...      -0.006831   Normal  \n",
       "1   (ColumnTransformer(transformers=[('min_max_sca...       0.001361   Normal  \n",
       "9   (ColumnTransformer(transformers=[('min_max_sca...      -0.002448   Normal  \n",
       "6   (ColumnTransformer(transformers=[('min_max_sca...       0.564935  Overfit  \n",
       "5   (ColumnTransformer(transformers=[('min_max_sca...       0.000006   Normal  \n",
       "2   (ColumnTransformer(transformers=[('min_max_sca...       0.431105   Normal  \n",
       "3   (ColumnTransformer(transformers=[('min_max_sca...       9.377083  Overfit  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = [model_reglog, model_svm, model_gnb, model_dt, model_ranfor, model_adb, model_xtr, model_MLPerp,\n",
    "          model_XGBoos, model_cast, model_lgb]\n",
    "df_model_results = me.ranking_models(models)\n",
    "df_model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Score_Train</th>\n",
       "      <th>Score_Test</th>\n",
       "      <th>Auc_Roc</th>\n",
       "      <th>Log_loss_Train</th>\n",
       "      <th>Log_loss_Test</th>\n",
       "      <th>Mean_Acc_Score</th>\n",
       "      <th>Std_Acc_Score</th>\n",
       "      <th>Model_Run</th>\n",
       "      <th>Diff_log_loss</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Extra_Trees</td>\n",
       "      <td>99.94</td>\n",
       "      <td>81.25</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.000888</td>\n",
       "      <td>0.565823</td>\n",
       "      <td>80.50</td>\n",
       "      <td>0.74</td>\n",
       "      <td>(ColumnTransformer(transformers=[('min_max_sca...</td>\n",
       "      <td>0.564935</td>\n",
       "      <td>Overfit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision_Tree</td>\n",
       "      <td>99.94</td>\n",
       "      <td>72.82</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.000888</td>\n",
       "      <td>9.377971</td>\n",
       "      <td>72.53</td>\n",
       "      <td>0.91</td>\n",
       "      <td>(ColumnTransformer(transformers=[('min_max_sca...</td>\n",
       "      <td>9.377083</td>\n",
       "      <td>Overfit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random_Forest</td>\n",
       "      <td>99.94</td>\n",
       "      <td>82.20</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.113638</td>\n",
       "      <td>0.445196</td>\n",
       "      <td>81.39</td>\n",
       "      <td>0.59</td>\n",
       "      <td>(ColumnTransformer(transformers=[('min_max_sca...</td>\n",
       "      <td>0.331559</td>\n",
       "      <td>Overfit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>88.37</td>\n",
       "      <td>81.42</td>\n",
       "      <td>94.45</td>\n",
       "      <td>0.280217</td>\n",
       "      <td>0.444547</td>\n",
       "      <td>81.39</td>\n",
       "      <td>0.77</td>\n",
       "      <td>(ColumnTransformer(transformers=[('min_max_sca...</td>\n",
       "      <td>0.164330</td>\n",
       "      <td>Overfit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MLPerceptron</td>\n",
       "      <td>82.00</td>\n",
       "      <td>82.18</td>\n",
       "      <td>77.60</td>\n",
       "      <td>0.431045</td>\n",
       "      <td>0.428954</td>\n",
       "      <td>81.93</td>\n",
       "      <td>0.63</td>\n",
       "      <td>(ColumnTransformer(transformers=[('min_max_sca...</td>\n",
       "      <td>-0.002091</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic_Regression</td>\n",
       "      <td>82.02</td>\n",
       "      <td>82.15</td>\n",
       "      <td>76.73</td>\n",
       "      <td>0.438033</td>\n",
       "      <td>0.437253</td>\n",
       "      <td>81.98</td>\n",
       "      <td>0.68</td>\n",
       "      <td>(ColumnTransformer(transformers=[('min_max_sca...</td>\n",
       "      <td>-0.000780</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Support_Vector_Mac</td>\n",
       "      <td>82.01</td>\n",
       "      <td>82.02</td>\n",
       "      <td>75.77</td>\n",
       "      <td>0.447135</td>\n",
       "      <td>0.448496</td>\n",
       "      <td>81.80</td>\n",
       "      <td>0.54</td>\n",
       "      <td>(ColumnTransformer(transformers=[('min_max_sca...</td>\n",
       "      <td>0.001361</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>lgbBoost</td>\n",
       "      <td>80.10</td>\n",
       "      <td>80.62</td>\n",
       "      <td>75.24</td>\n",
       "      <td>0.453577</td>\n",
       "      <td>0.446746</td>\n",
       "      <td>80.06</td>\n",
       "      <td>0.52</td>\n",
       "      <td>(ColumnTransformer(transformers=[('min_max_sca...</td>\n",
       "      <td>-0.006831</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>81.95</td>\n",
       "      <td>82.00</td>\n",
       "      <td>76.61</td>\n",
       "      <td>0.470352</td>\n",
       "      <td>0.467904</td>\n",
       "      <td>81.92</td>\n",
       "      <td>0.61</td>\n",
       "      <td>(ColumnTransformer(transformers=[('min_max_sca...</td>\n",
       "      <td>-0.002448</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>81.88</td>\n",
       "      <td>82.07</td>\n",
       "      <td>78.31</td>\n",
       "      <td>0.677516</td>\n",
       "      <td>0.677522</td>\n",
       "      <td>81.73</td>\n",
       "      <td>0.69</td>\n",
       "      <td>(ColumnTransformer(transformers=[('min_max_sca...</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gaussian_NB</td>\n",
       "      <td>76.51</td>\n",
       "      <td>77.40</td>\n",
       "      <td>67.00</td>\n",
       "      <td>1.180029</td>\n",
       "      <td>1.611133</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(ColumnTransformer(transformers=[('min_max_sca...</td>\n",
       "      <td>0.431105</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model  Score_Train  Score_Test  Auc_Roc  Log_loss_Train  \\\n",
       "6           Extra_Trees        99.94       81.25   100.00        0.000888   \n",
       "3         Decision_Tree        99.94       72.82   100.00        0.000888   \n",
       "4         Random_Forest        99.94       82.20   100.00        0.113638   \n",
       "8               XGBoost        88.37       81.42    94.45        0.280217   \n",
       "7          MLPerceptron        82.00       82.18    77.60        0.431045   \n",
       "0   Logistic_Regression        82.02       82.15    76.73        0.438033   \n",
       "1    Support_Vector_Mac        82.01       82.02    75.77        0.447135   \n",
       "10             lgbBoost        80.10       80.62    75.24        0.453577   \n",
       "9              CatBoost        81.95       82.00    76.61        0.470352   \n",
       "5              AdaBoost        81.88       82.07    78.31        0.677516   \n",
       "2           Gaussian_NB        76.51       77.40    67.00        1.180029   \n",
       "\n",
       "    Log_loss_Test  Mean_Acc_Score  Std_Acc_Score  \\\n",
       "6        0.565823           80.50           0.74   \n",
       "3        9.377971           72.53           0.91   \n",
       "4        0.445196           81.39           0.59   \n",
       "8        0.444547           81.39           0.77   \n",
       "7        0.428954           81.93           0.63   \n",
       "0        0.437253           81.98           0.68   \n",
       "1        0.448496           81.80           0.54   \n",
       "10       0.446746           80.06           0.52   \n",
       "9        0.467904           81.92           0.61   \n",
       "5        0.677522           81.73           0.69   \n",
       "2        1.611133             NaN            NaN   \n",
       "\n",
       "                                            Model_Run  Diff_log_loss   Status  \n",
       "6   (ColumnTransformer(transformers=[('min_max_sca...       0.564935  Overfit  \n",
       "3   (ColumnTransformer(transformers=[('min_max_sca...       9.377083  Overfit  \n",
       "4   (ColumnTransformer(transformers=[('min_max_sca...       0.331559  Overfit  \n",
       "8   (ColumnTransformer(transformers=[('min_max_sca...       0.164330  Overfit  \n",
       "7   (ColumnTransformer(transformers=[('min_max_sca...      -0.002091   Normal  \n",
       "0   (ColumnTransformer(transformers=[('min_max_sca...      -0.000780   Normal  \n",
       "1   (ColumnTransformer(transformers=[('min_max_sca...       0.001361   Normal  \n",
       "10  (ColumnTransformer(transformers=[('min_max_sca...      -0.006831   Normal  \n",
       "9   (ColumnTransformer(transformers=[('min_max_sca...      -0.002448   Normal  \n",
       "5   (ColumnTransformer(transformers=[('min_max_sca...       0.000006   Normal  \n",
       "2   (ColumnTransformer(transformers=[('min_max_sca...       0.431105   Normal  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model_results.sort_values(by = [\"Log_loss_Train\", \"Mean_Acc_Score\", \"Auc_Roc\", \"Log_loss_Test\"],\n",
    "                ascending = [True, False, False, True])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    ">> Conclusion: \n",
    "    The following models were chosen to be optimized: Extra Trees, Random Forest, XGBoost and MLPerceptron\n",
    "    The following models were chosen to be discarded: Missed NB, Decision Tree and AdaBoost\n",
    "    The rest of models can be analysed futhermore: Logistic Regression, SVM, Light and CatBoost\n",
    "\n",
    "Criteria decision: smaller training log loss, greater auc-roc and better mean-accuracy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chosen models Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra Trees, Random Forest, XGBoost and MLPerceptron\n",
    "# afterwards: run voting and stacking in order to check better perfomance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stratified kfold\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n"
     ]
    }
   ],
   "source": [
    "# executing Random Forest optimization\n",
    "model_rf = Pipeline(steps=[('pre_processor', pre_processador), ('model', RandomForestClassifier(random_state=123))])\n",
    "\n",
    "# defining hyperparameters\n",
    "criterion = [\"gini\", \"entropy\"]\n",
    "min_samples_leaf = [1, 5, 10,]\n",
    "min_samples_split = [2, 4, 10,]\n",
    "n_estimators = [10, 20, 30, 40, 50, 60, 100, 120, 150, 200, 250, 300, 500,]\n",
    "max_depth = [2, 4, 6, 8, 10, 12, 20,]\n",
    "param_grid = dict(model__criterion = criterion, \\\n",
    "                  model__min_samples_leaf = min_samples_leaf, \\\n",
    "                  model__min_samples_split = min_samples_split, \\\n",
    "                  model__n_estimators = n_estimators, \\\n",
    "                  model__max_depth = max_depth)\n",
    "\n",
    "# finding best parameters\n",
    "grid_rf = RandomizedSearchCV(model_rf, param_grid, n_iter=100, cv=skf, scoring='accuracy', \\\n",
    "                             verbose=1, random_state=123, n_jobs=-1)\n",
    "\n",
    "# training best parameters\n",
    "grid_rf.fit(X_train, y_train)\n",
    "\n",
    "rf_best = grid_rf.best_estimator_ # saving the best hyperparameters definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n"
     ]
    }
   ],
   "source": [
    "# executing Extra Trees optimization\n",
    "model_extratrees = Pipeline(steps=[('pre_processor', pre_processador), ('model', ExtraTreesClassifier(random_state=123))])\n",
    "\n",
    "# defining hyperparameters\n",
    "criterion = [\"gini\", \"entropy\"]\n",
    "min_samples_leaf = [1, 3, 5, 8, 10,]\n",
    "min_samples_split = [1, 2, 3, ]\n",
    "n_estimators = [10, 20, 30, 40, 50, 60, 100, ]\n",
    "max_depth = [2, 4, 6, ]\n",
    "max_features = [\"auto\", \"sqrt\", \"log2\"]\n",
    "bootstrap = [True, False]\n",
    "warm_start = [True, False]\n",
    "max_samples = [0, 1, 2, 3, 4, 5]\n",
    "n_iter = [50, 100, 150]\n",
    "param_grid = dict(model__criterion = criterion, \\\n",
    "                  model__min_samples_leaf = min_samples_leaf, \\\n",
    "                  model__min_samples_split = min_samples_split, \\\n",
    "                  model__n_estimators = n_estimators, \\\n",
    "                  model__max_depth = max_depth, \\\n",
    "                  model__max_features = max_features, \\\n",
    "                  model__bootstrap = bootstrap, \\\n",
    "                  model__warm_start = warm_start, \\\n",
    "                  model__max_samples = max_samples)\n",
    "\n",
    "# finding best parameters\n",
    "grid_xtree = RandomizedSearchCV(model_extratrees, param_grid, n_iter=100, cv=skf, scoring='accuracy', \\\n",
    "                             verbose=1, random_state=123, n_jobs=-1)\n",
    "\n",
    "# training best parameters\n",
    "grid_xtree.fit(X_train, y_train)\n",
    "\n",
    "xtree_best = grid_xtree.best_estimator_ # saving the best hyperparameters definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    }
   ],
   "source": [
    "# executing Multi layer perceptron optimization\n",
    "model_MLP = Pipeline(steps=[('pre_processor', pre_processador),\n",
    "                ('model', MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1) )])\n",
    "\n",
    "# defining hyperparameters\n",
    "hidden_layer_sizes = [50, 100, 150, 200, 250, 300, ]\n",
    "activation = ['tanh']\n",
    "solver = ['lbfgs']\n",
    "alpha = loguniform(1e-2, 1)\n",
    "batch_size = [50, 100, 150, 200, 250, 300, ]\n",
    "learning_rate=['adaptive']\n",
    "max_iter = [10, 20, 30, 40, 50, 60, 100, 120, 150, 200, 250, 300, 350, 400, 500,]\n",
    "max_fun = [1000, 1500, 2000, 2500]\n",
    "n_iter_no_change = [2, 4, 6, 8, 10, 12, 20,]\n",
    "param_grid = dict(model__hidden_layer_sizes = hidden_layer_sizes, \\\n",
    "                  model__activation = activation, \\\n",
    "                  model__solver = solver, \\\n",
    "                  model__alpha = alpha, \\\n",
    "                  model__batch_size = batch_size, \\\n",
    "                  model__learning_rate = learning_rate, \\\n",
    "                  model__max_iter = max_iter, \\\n",
    "                  model__max_fun = max_fun, \\\n",
    "                  model__n_iter_no_change = n_iter_no_change)\n",
    "\n",
    "# finding best parameters\n",
    "grid_MLP = RandomizedSearchCV(model_MLP, param_grid,  n_iter=10, cv=skf, scoring='accuracy', \\\n",
    "                              verbose=1, random_state=123, n_jobs=-1)\n",
    "\n",
    "# training best parameters\n",
    "grid_MLP.fit(X_train, y_train)\n",
    "\n",
    "MLP_best = grid_MLP.best_estimator_ # saving the best hyperparameters definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
      "[09:50:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "# executing XGBoost optimization\n",
    "model_xgb = Pipeline(steps=[('pre_processor', pre_processador), ('model', XGBClassifier() )])\n",
    "\n",
    "\n",
    "# definition of hyper parameters for XGBoost Classifier\n",
    "learning_rate = [0.1, 0.01, 0.001]\n",
    "gamma = [0.01, 0.1, 0.3, 0.5, 1, 1.5, 2]\n",
    "max_depth = [2, 4, 6, 8, 10, 12, 20, 30]\n",
    "colsample_bytree = [0.3, 0.6, 0.8, 1.0]\n",
    "subsample = [0.2, 0.4, 0.5, 0.6, 0.7]\n",
    "reg_alpha = [0, 0.5, 1]\n",
    "reg_lambda =  [1, 1.5, 2, 3, 4.5]\n",
    "min_child_weight = [1, 3, 5, 7]\n",
    "n_estimators = [10, 20, 30, 40, 50, 60, 100, 120, 150, 200, 250, 300, 500]\n",
    "\n",
    "param_grid = dict(model__learning_rate = learning_rate, \\\n",
    "                  model__gamma = gamma, \\\n",
    "                  model__colsample_bytree = colsample_bytree, \\\n",
    "                  model__n_estimators = n_estimators, \\\n",
    "                  model__max_depth = max_depth, \\\n",
    "                  model__subsample = subsample, \\\n",
    "                  model__reg_alpha = reg_alpha, \\\n",
    "                  model__reg_lambda = reg_lambda, \\\n",
    "                  model__min_child_weight = min_child_weight)\n",
    "\n",
    "# finding best parameters\n",
    "grid_xgb = RandomizedSearchCV(model_xgb, param_grid,  n_iter=100, cv=skf, scoring='accuracy', \\\n",
    "                             verbose=1, random_state=123, n_jobs=-1)\n",
    "\n",
    "# training best parameters\n",
    "grid_xgb.fit(X_train, y_train)\n",
    "\n",
    "xgb_best = grid_xgb.best_estimator_ # saving the best hyperparameters definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:13:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:13:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:13:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:13:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:13:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:14:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:14:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:14:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:14:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:14:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:14:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Score_Train</th>\n",
       "      <th>Score_Test</th>\n",
       "      <th>Auc_Roc</th>\n",
       "      <th>Log_loss_Train</th>\n",
       "      <th>Log_loss_Test</th>\n",
       "      <th>Mean_Acc_Score</th>\n",
       "      <th>Std_Acc_Score</th>\n",
       "      <th>Model_Run</th>\n",
       "      <th>Diff_log_loss</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF_Best</td>\n",
       "      <td>84.65</td>\n",
       "      <td>82.38</td>\n",
       "      <td>86.13</td>\n",
       "      <td>0.371818</td>\n",
       "      <td>0.422352</td>\n",
       "      <td>82.08</td>\n",
       "      <td>0.70</td>\n",
       "      <td>(ColumnTransformer(transformers=[('min_max_sca...</td>\n",
       "      <td>0.050535</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MLP_Best</td>\n",
       "      <td>81.96</td>\n",
       "      <td>82.03</td>\n",
       "      <td>77.11</td>\n",
       "      <td>0.435276</td>\n",
       "      <td>0.433801</td>\n",
       "      <td>81.90</td>\n",
       "      <td>0.67</td>\n",
       "      <td>(ColumnTransformer(transformers=[('min_max_sca...</td>\n",
       "      <td>-0.001475</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XTREE_Best</td>\n",
       "      <td>82.01</td>\n",
       "      <td>81.87</td>\n",
       "      <td>77.28</td>\n",
       "      <td>0.437387</td>\n",
       "      <td>0.438278</td>\n",
       "      <td>81.70</td>\n",
       "      <td>0.72</td>\n",
       "      <td>(ColumnTransformer(transformers=[('min_max_sca...</td>\n",
       "      <td>0.000891</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGB_Best</td>\n",
       "      <td>82.98</td>\n",
       "      <td>82.15</td>\n",
       "      <td>79.69</td>\n",
       "      <td>0.643485</td>\n",
       "      <td>0.644737</td>\n",
       "      <td>82.10</td>\n",
       "      <td>0.78</td>\n",
       "      <td>(ColumnTransformer(transformers=[('min_max_sca...</td>\n",
       "      <td>0.001252</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Model  Score_Train  Score_Test  Auc_Roc  Log_loss_Train  \\\n",
       "0     RF_Best        84.65       82.38    86.13        0.371818   \n",
       "1    MLP_Best        81.96       82.03    77.11        0.435276   \n",
       "2  XTREE_Best        82.01       81.87    77.28        0.437387   \n",
       "3    XGB_Best        82.98       82.15    79.69        0.643485   \n",
       "\n",
       "   Log_loss_Test  Mean_Acc_Score  Std_Acc_Score  \\\n",
       "0       0.422352           82.08           0.70   \n",
       "1       0.433801           81.90           0.67   \n",
       "2       0.438278           81.70           0.72   \n",
       "3       0.644737           82.10           0.78   \n",
       "\n",
       "                                           Model_Run  Diff_log_loss  Status  \n",
       "0  (ColumnTransformer(transformers=[('min_max_sca...       0.050535  Normal  \n",
       "1  (ColumnTransformer(transformers=[('min_max_sca...      -0.001475  Normal  \n",
       "2  (ColumnTransformer(transformers=[('min_max_sca...       0.000891  Normal  \n",
       "3  (ColumnTransformer(transformers=[('min_max_sca...       0.001252  Normal  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# running models with the best hyperparameters and getting measures\n",
    "\n",
    "# rf_best\n",
    "rf_best_params = measure_best_model(rf_best, pre_processador, 'RF_Best', X_train, y_train, X_test, y_test)\n",
    "\n",
    "# MLP_best\n",
    "MLP_best_params = measure_best_model(MLP_best, pre_processador, 'MLP_Best', X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Xtree_best\n",
    "xtree_best_params = measure_best_model(xtree_best, pre_processador, 'XTREE_Best', X_train, y_train, X_test, y_test)\n",
    "\n",
    "# XGB_best\n",
    "xgb_best_params = measure_best_model(xgb_best, pre_processador, 'XGB_Best', X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Ranking peformances of the best models chosen\n",
    "models = [rf_best_params, MLP_best_params, xtree_best_params, xgb_best_params]\n",
    "df_model_results_best = me.ranking_models(models)\n",
    "df_model_results_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combing Models:\n",
    "models = [ ('MLP', MLP_best), ('rf', rf_best), ('xtree', xtree_best), ('xgb', xgb_best) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:22:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('MLP',\n",
       "                              Pipeline(steps=[('pre_processor',\n",
       "                                               ColumnTransformer(transformers=[('min_max_scaler',\n",
       "                                                                                MinMaxScaler(),\n",
       "                                                                                ['AGE']),\n",
       "                                                                               ('one_hot_encoder',\n",
       "                                                                                OneHotEncoder(handle_unknown='ignore'),\n",
       "                                                                                ['SEX',\n",
       "                                                                                 'MARRIAGE']),\n",
       "                                                                               ('ordinal_encoder',\n",
       "                                                                                OrdinalEncoder(),\n",
       "                                                                                ['EDUCATION']),\n",
       "                                                                               ('target_encoder',\n",
       "                                                                                TargetEncoder(),\n",
       "                                                                                ['PAY_0',\n",
       "                                                                                 'PAY_2',\n",
       "                                                                                 'PAY_3',\n",
       "                                                                                 'PAY_4',\n",
       "                                                                                 'PAY_5',\n",
       "                                                                                 'PA...\n",
       "                                                             importance_type='gain',\n",
       "                                                             interaction_constraints='',\n",
       "                                                             learning_rate=0.001,\n",
       "                                                             max_delta_step=0,\n",
       "                                                             max_depth=10,\n",
       "                                                             min_child_weight=3,\n",
       "                                                             missing=nan,\n",
       "                                                             monotone_constraints='()',\n",
       "                                                             n_estimators=120,\n",
       "                                                             n_jobs=8,\n",
       "                                                             num_parallel_tree=1,\n",
       "                                                             random_state=0,\n",
       "                                                             reg_alpha=1,\n",
       "                                                             reg_lambda=3,\n",
       "                                                             scale_pos_weight=1,\n",
       "                                                             subsample=0.4,\n",
       "                                                             tree_method='exact',\n",
       "                                                             validate_parameters=1,\n",
       "                                                             verbosity=None))]))],\n",
       "                 voting='soft')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training voting classifier with the best models optimized\n",
    "model_vote = VotingClassifier(estimators=models, voting='soft')\n",
    "model_vote.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:23:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:24:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:24:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:24:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:24:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:24:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StackingClassifier(estimators=[('MLP',\n",
       "                                Pipeline(steps=[('pre_processor',\n",
       "                                                 ColumnTransformer(transformers=[('min_max_scaler',\n",
       "                                                                                  MinMaxScaler(),\n",
       "                                                                                  ['AGE']),\n",
       "                                                                                 ('one_hot_encoder',\n",
       "                                                                                  OneHotEncoder(handle_unknown='ignore'),\n",
       "                                                                                  ['SEX',\n",
       "                                                                                   'MARRIAGE']),\n",
       "                                                                                 ('ordinal_encoder',\n",
       "                                                                                  OrdinalEncoder(),\n",
       "                                                                                  ['EDUCATION']),\n",
       "                                                                                 ('target_encoder',\n",
       "                                                                                  TargetEncoder(),\n",
       "                                                                                  ['PAY_0',\n",
       "                                                                                   'PAY_2',\n",
       "                                                                                   'PAY_3',\n",
       "                                                                                   'PAY_4',\n",
       "                                                                                   'PAY_5',\n",
       "                                                                                   '...\n",
       "                                                               gamma=0.3,\n",
       "                                                               gpu_id=-1,\n",
       "                                                               importance_type='gain',\n",
       "                                                               interaction_constraints='',\n",
       "                                                               learning_rate=0.001,\n",
       "                                                               max_delta_step=0,\n",
       "                                                               max_depth=10,\n",
       "                                                               min_child_weight=3,\n",
       "                                                               missing=nan,\n",
       "                                                               monotone_constraints='()',\n",
       "                                                               n_estimators=120,\n",
       "                                                               n_jobs=8,\n",
       "                                                               num_parallel_tree=1,\n",
       "                                                               random_state=0,\n",
       "                                                               reg_alpha=1,\n",
       "                                                               reg_lambda=3,\n",
       "                                                               scale_pos_weight=1,\n",
       "                                                               subsample=0.4,\n",
       "                                                               tree_method='exact',\n",
       "                                                               validate_parameters=1,\n",
       "                                                               verbosity=None))]))])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training stacking classifier with the best models optimized\n",
    "model_stack = StackingClassifier(estimators=models)\n",
    "model_stack.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:25:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:25:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:25:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:26:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:26:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:26:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:27:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:27:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:28:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:28:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:28:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:29:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:30:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:30:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:30:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:30:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:30:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:31:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:32:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:32:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:32:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:32:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:32:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:33:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:34:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:34:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:34:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:34:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:34:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:34:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:36:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:36:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:36:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:36:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:36:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:36:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:37:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:37:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:38:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:38:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:38:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:38:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:39:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:39:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:39:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:39:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:39:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:40:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:41:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:41:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:41:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:41:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:41:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:42:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:43:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:43:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:43:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:43:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:43:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:44:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:45:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:45:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:45:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:45:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:45:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:45:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:47:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:47:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:47:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:47:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:47:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:47:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:48:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:48:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:48:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:48:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:49:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Score_Train</th>\n",
       "      <th>Score_Test</th>\n",
       "      <th>Auc_Roc</th>\n",
       "      <th>Log_loss_Train</th>\n",
       "      <th>Log_loss_Test</th>\n",
       "      <th>Mean_Acc_Score</th>\n",
       "      <th>Std_Acc_Score</th>\n",
       "      <th>Model_Run</th>\n",
       "      <th>Diff_log_loss</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF_Best</td>\n",
       "      <td>84.65</td>\n",
       "      <td>82.38</td>\n",
       "      <td>86.13</td>\n",
       "      <td>0.371818</td>\n",
       "      <td>0.422352</td>\n",
       "      <td>82.08</td>\n",
       "      <td>0.70</td>\n",
       "      <td>(ColumnTransformer(transformers=[('min_max_sca...</td>\n",
       "      <td>0.050535</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Stack_Best</td>\n",
       "      <td>84.45</td>\n",
       "      <td>82.28</td>\n",
       "      <td>85.76</td>\n",
       "      <td>0.378047</td>\n",
       "      <td>0.425592</td>\n",
       "      <td>82.11</td>\n",
       "      <td>0.68</td>\n",
       "      <td>StackingClassifier(estimators=[('MLP',\\n      ...</td>\n",
       "      <td>0.047545</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MLP_Best</td>\n",
       "      <td>81.96</td>\n",
       "      <td>82.03</td>\n",
       "      <td>77.11</td>\n",
       "      <td>0.435276</td>\n",
       "      <td>0.433801</td>\n",
       "      <td>81.90</td>\n",
       "      <td>0.67</td>\n",
       "      <td>(ColumnTransformer(transformers=[('min_max_sca...</td>\n",
       "      <td>-0.001475</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XTREE_Best</td>\n",
       "      <td>82.01</td>\n",
       "      <td>81.87</td>\n",
       "      <td>77.28</td>\n",
       "      <td>0.437387</td>\n",
       "      <td>0.438278</td>\n",
       "      <td>81.70</td>\n",
       "      <td>0.72</td>\n",
       "      <td>(ColumnTransformer(transformers=[('min_max_sca...</td>\n",
       "      <td>0.000891</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vote_Best</td>\n",
       "      <td>83.02</td>\n",
       "      <td>82.25</td>\n",
       "      <td>81.91</td>\n",
       "      <td>0.441866</td>\n",
       "      <td>0.453459</td>\n",
       "      <td>82.07</td>\n",
       "      <td>0.77</td>\n",
       "      <td>VotingClassifier(estimators=[('MLP',\\n        ...</td>\n",
       "      <td>0.011594</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGB_Best</td>\n",
       "      <td>82.98</td>\n",
       "      <td>82.15</td>\n",
       "      <td>79.69</td>\n",
       "      <td>0.643485</td>\n",
       "      <td>0.644737</td>\n",
       "      <td>82.10</td>\n",
       "      <td>0.78</td>\n",
       "      <td>(ColumnTransformer(transformers=[('min_max_sca...</td>\n",
       "      <td>0.001252</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Model  Score_Train  Score_Test  Auc_Roc  Log_loss_Train  \\\n",
       "0     RF_Best        84.65       82.38    86.13        0.371818   \n",
       "5  Stack_Best        84.45       82.28    85.76        0.378047   \n",
       "1    MLP_Best        81.96       82.03    77.11        0.435276   \n",
       "2  XTREE_Best        82.01       81.87    77.28        0.437387   \n",
       "4   Vote_Best        83.02       82.25    81.91        0.441866   \n",
       "3    XGB_Best        82.98       82.15    79.69        0.643485   \n",
       "\n",
       "   Log_loss_Test  Mean_Acc_Score  Std_Acc_Score  \\\n",
       "0       0.422352           82.08           0.70   \n",
       "5       0.425592           82.11           0.68   \n",
       "1       0.433801           81.90           0.67   \n",
       "2       0.438278           81.70           0.72   \n",
       "4       0.453459           82.07           0.77   \n",
       "3       0.644737           82.10           0.78   \n",
       "\n",
       "                                           Model_Run  Diff_log_loss  Status  \n",
       "0  (ColumnTransformer(transformers=[('min_max_sca...       0.050535  Normal  \n",
       "5  StackingClassifier(estimators=[('MLP',\\n      ...       0.047545  Normal  \n",
       "1  (ColumnTransformer(transformers=[('min_max_sca...      -0.001475  Normal  \n",
       "2  (ColumnTransformer(transformers=[('min_max_sca...       0.000891  Normal  \n",
       "4  VotingClassifier(estimators=[('MLP',\\n        ...       0.011594  Normal  \n",
       "3  (ColumnTransformer(transformers=[('min_max_sca...       0.001252  Normal  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ranking peformances of the best models chosen, including voting and stacking\n",
    "\n",
    "\n",
    "# Vote_parameters\n",
    "vote_best_params = measure_best_model(model_vote, pre_processador, 'Vote_Best', X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Stack_parameters\n",
    "stack_best_params = measure_best_model(model_stack, pre_processador, 'Stack_Best', X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Ranking peformances of the best models chosen, including voting and stacking\n",
    "models = [rf_best_params, MLP_best_params, xtree_best_params, xgb_best_params, vote_best_params, stack_best_params]\n",
    "df_model_results_best = me.ranking_models(models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Score_Train</th>\n",
       "      <th>Score_Test</th>\n",
       "      <th>Auc_Roc</th>\n",
       "      <th>Log_loss_Train</th>\n",
       "      <th>Log_loss_Test</th>\n",
       "      <th>Mean_Acc_Score</th>\n",
       "      <th>Std_Acc_Score</th>\n",
       "      <th>Model_Run</th>\n",
       "      <th>Diff_log_loss</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF_Best</td>\n",
       "      <td>84.65</td>\n",
       "      <td>82.38</td>\n",
       "      <td>86.13</td>\n",
       "      <td>0.371818</td>\n",
       "      <td>0.422352</td>\n",
       "      <td>82.08</td>\n",
       "      <td>0.70</td>\n",
       "      <td>(ColumnTransformer(transformers=[('min_max_sca...</td>\n",
       "      <td>0.050535</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Stack_Best</td>\n",
       "      <td>84.45</td>\n",
       "      <td>82.28</td>\n",
       "      <td>85.76</td>\n",
       "      <td>0.378047</td>\n",
       "      <td>0.425592</td>\n",
       "      <td>82.11</td>\n",
       "      <td>0.68</td>\n",
       "      <td>StackingClassifier(estimators=[('MLP',\\n      ...</td>\n",
       "      <td>0.047545</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MLP_Best</td>\n",
       "      <td>81.96</td>\n",
       "      <td>82.03</td>\n",
       "      <td>77.11</td>\n",
       "      <td>0.435276</td>\n",
       "      <td>0.433801</td>\n",
       "      <td>81.90</td>\n",
       "      <td>0.67</td>\n",
       "      <td>(ColumnTransformer(transformers=[('min_max_sca...</td>\n",
       "      <td>-0.001475</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XTREE_Best</td>\n",
       "      <td>82.01</td>\n",
       "      <td>81.87</td>\n",
       "      <td>77.28</td>\n",
       "      <td>0.437387</td>\n",
       "      <td>0.438278</td>\n",
       "      <td>81.70</td>\n",
       "      <td>0.72</td>\n",
       "      <td>(ColumnTransformer(transformers=[('min_max_sca...</td>\n",
       "      <td>0.000891</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vote_Best</td>\n",
       "      <td>83.02</td>\n",
       "      <td>82.25</td>\n",
       "      <td>81.91</td>\n",
       "      <td>0.441866</td>\n",
       "      <td>0.453459</td>\n",
       "      <td>82.07</td>\n",
       "      <td>0.77</td>\n",
       "      <td>VotingClassifier(estimators=[('MLP',\\n        ...</td>\n",
       "      <td>0.011594</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGB_Best</td>\n",
       "      <td>82.98</td>\n",
       "      <td>82.15</td>\n",
       "      <td>79.69</td>\n",
       "      <td>0.643485</td>\n",
       "      <td>0.644737</td>\n",
       "      <td>82.10</td>\n",
       "      <td>0.78</td>\n",
       "      <td>(ColumnTransformer(transformers=[('min_max_sca...</td>\n",
       "      <td>0.001252</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Model  Score_Train  Score_Test  Auc_Roc  Log_loss_Train  \\\n",
       "0     RF_Best        84.65       82.38    86.13        0.371818   \n",
       "5  Stack_Best        84.45       82.28    85.76        0.378047   \n",
       "1    MLP_Best        81.96       82.03    77.11        0.435276   \n",
       "2  XTREE_Best        82.01       81.87    77.28        0.437387   \n",
       "4   Vote_Best        83.02       82.25    81.91        0.441866   \n",
       "3    XGB_Best        82.98       82.15    79.69        0.643485   \n",
       "\n",
       "   Log_loss_Test  Mean_Acc_Score  Std_Acc_Score  \\\n",
       "0       0.422352           82.08           0.70   \n",
       "5       0.425592           82.11           0.68   \n",
       "1       0.433801           81.90           0.67   \n",
       "2       0.438278           81.70           0.72   \n",
       "4       0.453459           82.07           0.77   \n",
       "3       0.644737           82.10           0.78   \n",
       "\n",
       "                                           Model_Run  Diff_log_loss  Status  \n",
       "0  (ColumnTransformer(transformers=[('min_max_sca...       0.050535  Normal  \n",
       "5  StackingClassifier(estimators=[('MLP',\\n      ...       0.047545  Normal  \n",
       "1  (ColumnTransformer(transformers=[('min_max_sca...      -0.001475  Normal  \n",
       "2  (ColumnTransformer(transformers=[('min_max_sca...       0.000891  Normal  \n",
       "4  VotingClassifier(estimators=[('MLP',\\n        ...       0.011594  Normal  \n",
       "3  (ColumnTransformer(transformers=[('min_max_sca...       0.001252  Normal  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model_results_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('pre_processor',\n",
       "                 ColumnTransformer(transformers=[('min_max_scaler',\n",
       "                                                  MinMaxScaler(), ['AGE']),\n",
       "                                                 ('one_hot_encoder',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
       "                                                  ['SEX', 'MARRIAGE']),\n",
       "                                                 ('ordinal_encoder',\n",
       "                                                  OrdinalEncoder(),\n",
       "                                                  ['EDUCATION']),\n",
       "                                                 ('target_encoder',\n",
       "                                                  TargetEncoder(),\n",
       "                                                  ['PAY_0', 'PAY_2', 'PAY_3',\n",
       "                                                   'PAY_4', 'PAY_5', 'PAY_6']),\n",
       "                                                 ('standard_scaler',\n",
       "                                                  StandardScaler(),\n",
       "                                                  ['LIMIT_BAL', 'BILL_AMT1',\n",
       "                                                   'BILL_AMT2', 'BILL_AMT3',\n",
       "                                                   'BILL_AMT4', 'PAY_AMT1',\n",
       "                                                   'PAY_AMT2', 'PAY_AMT3',\n",
       "                                                   'PAY_AMT4', 'PAY_AMT5',\n",
       "                                                   'PAY_AMT6', 'score'])])),\n",
       "                ('model',\n",
       "                 RandomForestClassifier(criterion='entropy', max_depth=10,\n",
       "                                        min_samples_split=4, n_estimators=300,\n",
       "                                        random_state=123))])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> Conclusion: optimized random forest resulted in the best measurements"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
